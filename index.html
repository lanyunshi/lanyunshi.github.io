<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yunshi Lan</title>
    <meta content="Yunshi Lan, https://lanyunshi.github.io" name="keywords">

    <style media="screen" type="text/css">
        html,
        body,
        div,
        span,
        applet,
        object,
        iframe,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6,
        p,
        blockquote,
        pre,
        a,
        abbr,
        acronym,
        address,
        big,
        cite,
        code,
        del,
        dfn,
        em,
        font,
        img,
        ins,
        kbd,
        q,
        s,
        samp,
        small,
        strike,
        strong,
        sub,
        tt,
        var,
        dl,
        dt,
        dd,
        ol,
        ul,
        li,
        fieldset,
        form,
        label,
        legend,
        table,
        caption,
        tbody,
        tfoot,
        thead,
        tr,
        th,
        td {
            border: 0pt none;
            font-family: inherit;
            font-size: 100%;
            font-style: inherit;
            font-weight: inherit;
            margin: 0pt;
            outline-color: invert;
            outline-style: none;
            outline-width: 0pt;
            padding: 0pt;
            vertical-align: baseline;
        }

        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }

        a.paper {
            font-weight: bold;
            font-size: 12pt;
        }

        b.paper {
            font-weight: bold;
            font-size: 12pt;
        }

        * {
            margin: 0pt;
            padding: 0pt;
        }

        body {
            position: relative;
            margin: 3em auto 2em auto;
            width: 800px;
            font-family: Verdana, Helvetica, sans-serif;
            font-size: 14px;
            background: #eee;
        }

        h2 {
            font-family: Verdana, Helvetica, sans-serif;
            font-size: 15pt;
            font-weight: 700;
        }

        h3 {
            font-family: Verdana, Helvetica, sans-serif;
            font-size: 16px;
            font-weight: 700;
        }

        strong {
            font-family: Verdana, Helvetica, sans-serif;
            font-size: 13px;
            font-weight: bold;
        }

        ul {
            list-style: circle;
        }

        img {
            border: none;
        }

        li {
            padding-bottom: 0.5em;
            margin-left: 1.4em;
        }

        alert {
            font-family: Verdana, Helvetica, sans-serif;
            font-size: 13px;
            font-weight: bold;
            color: #FF0000;
        }

        em,
        i {
            font-style: italic;
        }

        div.section {
            clear: both;
            margin-bottom: 1.5em;
            background: #eee;
        }

        div.spanner {
            clear: both;
        }

        div.paper {
            clear: both;
            margin-top: 0.5em;
            margin-bottom: 1em;
            border: 1px solid #ddd;
            background: #fff;
            padding: 1em 1em 1em 1em;
        }

        div.paper div {
            padding-left: 230px;
        }

        img.paper {
            margin-bottom: 0.5em;
            float: left;
            width: 200px;
        }

        span.blurb {
            font-style: italic;
            display: block;
            margin-top: 0.75em;
            margin-bottom: 0.5em;
        }

        pre,
        code {
            font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
            margin: 1em 0;
            padding: 0;
        }

        div.paper pre {
            font-size: 0.9em;
        }
    </style>


    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet"
          type="text/css"/>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164510176-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-164510176-1');
    </script>

</head>


<body>

    <!--photo and basic information-->
    <div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 130px;">
        <div style="margin: 0px auto; width: 100%;">
            <img title="yunshi" style="float: left; padding-left: .01em; height: 130px;"
                 src="./resources/images/me/me2.jpg">
            <div style="padding-left: 10em; vertical-align: top; height: 120px;">
                <span style="line-height: 150%; font-size: 20pt;">Yunshi Lan (兰韵诗)</span><br>
                <span><a href="http://dase.ecnu.edu.cn">School of Data Science and Engineering</a>, <a
                        href="https://www.ecnu.edu.cn">East China Normal University
                            (ECNU)</a></span><br>
                <span><strong>Address</strong>: 3663 North ZhongshanRd, Putuo District, Shanghai, China</span><br>
                <span><strong>Office</strong>: Room 203, Geography Building</span><br>
                <span><strong>Email</strong>: yslan [at] dase.ecnu.edu.cn</span> <br>
            </div>
        </div>
    </div>
    <!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

    
    <!--biography-->
    <div style="clear: both;">
        <div class="section">
            <h2>About Me (<a href="https://github.com/lanyunshi">[GitHub]</a>
                <a href="https://scholar.google.com/citations?user=Q0F92XIAAAAJ&hl=en">[Google Scholar]</a>
                <!-- <a href="./resources/cv/.pdf">[CV]</a>) -->
            </h2>
            <div class="paper">
                I am currently an Associate Professor at the <a href="https://faculty.ecnu.edu.cn/_s37/lys2/main.psp">School of Data Science & Engineering</a>, East China Normal University (ECNU). Before that, I was a research scientist at LARC, Singapore Management University (SMU). I obtained my Ph.D degree from School of Computing & Information System, Singapore Management University. I was trained (by my amazing supervisor <a href="http://www.mysmu.edu/faculty/jingjiang/">Prof. Jing Jiang</a> and secondary supervisor <a href="https://scholar.google.com/citations?user=uLa0zdcAAAAJ&hl=en">Prof. Feida Zhu)</a> to be a NLP researcher. I received my Bachelor degree from the School of Mathematics and Statistics, Southwest University (SWU).
                <br><br>
            </div>
        </div>
    </div>

    <!--Research Interest-->
    <div style="clear: both;">
        <div class="section">
            <h2>Research Interest
            </h2>
            <div class="paper">
                My recent research interest mainly includes knowledge bases, question answering, information extraction, text generation and deep learning.<br>
                <alert>I am looking for self-motivated students with strong programming skill to work with me. Please read this <a href="./resources/html/faq.html">FAQ</a> before emailing me!</alert>
                <br><br>
            </div>
        </div>
    </div>


    <!--News-->
    <div style="clear: both;">
        <div class="section">
            <h2 id="news">News</h2>
            <div class="paper">
                <ul>
                    <li>
                        2023-10: Two paper about Question Answering and Chain-of-Thought were accepted by EMNLP 2023.<br>
                        2023-09: One paper about FL on Object Detection was accepted by NeurIPS 2023.<br>
                        2023-08: One paper about Chinese Grammar Error Correction dataset was accepted by ACM CIKM 2023.<br>
                        2023-07: One paper about Knowledge Base Visual Question Answering was accepted by ACM MM 2023.<br>
                        2023-06: Rank First in the evaluation of NLPCC2023 Shared Task 8: Chinese Spelling Check.<br>
                        2023-05: Three papers about Question Answering, Math Word Problem Solving were accepted by ACL 2023.<br>
                        2023-04: One paper about FL on Object Detection was accepted by CVPR 2023.
                    </li>
                </ul>
                <div class="spanner"></div>
            </div>
        </div>
    </div>

    
    <!--Research Highlights-->
    <div style="clear: both;">
        <div class="section">
            <h2 id="confpapers">Research Highlights (<a href="https://scholar.google.com/citations?user=Q0F92XIAAAAJ&hl=en">[Full List]</a>)</h2>
            (* indicates equal contribution, # indicates corresponding author)


            <h4><alert>Question Answering</alert></h4>
            <div class="paper"><img class="paper" src="./resources/paper_icon/emnlp2023_kbqg.png"
                title="">
                <div><strong>Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation</strong><br>
                    Yuanyuan Liang, Jianing Wang, Hanlun Zhu, Lei Wang, <strong>Yunshi Lan</strong>, Weining Qian<br>
                    EMNLP, 2023 <br>
                    <br>
                    We leverage chain-of-thought to guide LLMs to generate complicated questions over knowledge base.
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/mm2023_kbvqa.png"
                title="">
                <div><strong>Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts</strong><br>
                    <strong>Yunshi Lan</strong>, Alex Xiang Li, Xin Liu, Yang Li, Wei Qin, Weining Qian<br>
                    ACM MM, 2023 <br>
                    <a href="./resources/bibtex/mm2023_kbvqa.txt">[BibTex]</a>
                    <br>
                    We propose a prompting method for visual question answering which can bridge the gap between questions and images.
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/tkde2022_survey.png"
                title="Complex Knowledge Base Question Answering: A Survey">
                <div><strong>Complex Knowledge Base Question Answering: A Survey</strong><br>
                    <strong>Yunshi Lan</strong>, Gaole He*, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao and Ji-Rong Wen<br>
                    TKDE, 2022 <br>
                    <a href="https://arxiv.org/pdf/2108.06688.pdf">[Paper]</a>
                    <a href="https://mp.weixin.qq.com/s/ZYGsB4AhgLyU0kuKWn9OlQ">[中文解读]</a>
                    <a href="https://github.com/RUCAIBox/Awesome-KBQA">[GitHub Page]</a>
                    <a href="./resources/bibtex/tkde2022_survey.txt">[BibTex]</a>
                    <br>
                    If you would like to know Knowledge Base Question Answering, please start from this survey!
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/acl2021_ckbqa.png"
                title="Modeling Transitions of Focal Entities for Conversational knowledge Base Question Answering">
                <div><strong>Modeling Transitions of Focal Entities for Conversational knowledge Base Question Answering</strong><br>
                    <strong>Yunshi Lan</strong>, Jing Jiang<br>
                    ACL, 2021 <br>
                    <a href="https://aclanthology.org/2021.acl-long.255.pdf">[Paper]</a>
                    <a href="./resources/bibtex/acl2021_ckbqa.txt">[BibTex]</a>
                    <br>
                    We propose a method for conversational knowledge base question answering tasks with the consideration of the transition of focal entitites.
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/wsdm2021_ckbqa.png"
                title="Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals">
                <div><strong>Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals</strong><br>
                    Gaole He, <strong>Yunshi Lan</strong>, Jing Jiang, Xin Zhao, Ji-Rong Wen<br>
                    WSDM, 2021 <br>
                    <a href="https://arxiv.org/pdf/2101.03737.pdf">[Paper]</a>
                    <a href="https://github.com/RichardHGL/WSDM2021_NSM">[GitHub Page]</a>
                    <a href="./resources/bibtex/wsdm2021_ckbqa.txt">[BibTex]</a>
                    <br>
                    We propose a method for multi-hop knowledge base question answering tasks with a Teacher-student framework.
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/acl2020_ckbqa.png"
                title="Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases">
                <div><strong>Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases</strong><br>
                    <strong>Yunshi Lan</strong>, Jing Jiang<br>
                    ACL, 2020 <br>
                    <a href="https://aclanthology.org/2020.acl-main.91.pdf">[Paper]</a>
                    <a href="https://github.com/lanyunshi/Multi-hopComplexKBQA">[GitHub Page]</a>
                    <a href="./resources/bibtex/acl2020_ckbqa.txt">[BibTex]</a>
                    <br>
                    We propose a method for multi-hop knowledge base question answering tasks with iterative path search.
                </div>
                <div class="spanner"></div>
            </div>
            <h4><alert>Educational NLP</alert></h4>
            <div class="paper"><img class="paper" src="./resources/paper_icon/edunlp_github.png"
                title="Paper List on Educational NLP">
                <div><strong>Paper List on Educational NLP</strong><br>
                    maintained by Keren Tan<br>
                    <a href="https://github.com/lanyunshi/EduNLP">[GitHub Page]</a>
                    <br>
                    We maintain a Github page for Educational NLP, which concludes existing studies on Educational NLP. We will keep updating it!
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/aaai2022_demo.png"
                title="MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers">
                <div><strong>MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers</strong><br>
                    Yihuai Lan, Lei Wang, Qiyuan Zhang, <strong>Yunshi Lan#</strong>, Bing Tian Dai, Yan Wang, Dongxiang Zhang, Ee-Peng Lim<br>
                    AAAI demo, 2022 <br>
                    <a href="https://arxiv.org/pdf/2109.00799.pdf">[Paper]</a>
                    <a href="https://mp.weixin.qq.com/s/2lLInVAMZ7s_8pc1A5Czjg">[中文解读]</a>
                    <a href="https://github.com/LYH-YF/MWPToolkit">[GitHub Page]</a>
                    <a href="./resources/bibtex/aaai2022_demo.txt">[BibTex]</a>
                    <br>
                    We develop a deep learning-based MWP toolkit, so that you can design your own MWP models effectively. Please feel free to try it out!
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/nlpcc2023_csc.png"
                title="Towards Robust Chinese Spelling Check Systems: Multi-round Error Correction with Ensemble Enhancement">
                <div><strong>Towards Robust Chinese Spelling Check Systems: Multi-round Error Correction with Ensemble Enhancement</strong><br>
                    Alex Xiang Li and Hanyue Du and Yike Zhao and <strong>Yunshi Lan#</strong><br>
                    NLPCC, evaluation paper, 2023 <br>
                    <a href="https://github.com/Ashura5/MECEE">[GitHub Page]</a>
                    <a href="https://github.com/Arvid-pku/NLPCC2023_Shared_Task8/tree/main">[Leaderboard]</a>
                    <a href="./resources/bibtex/nlpcc2023_csc.txt">[BibTex]</a>
                    <br>
                    We rank first in NLPCC 2023 shared task Chinese Spelling Check. Please check out our open-source solution.
                </div>
                <div class="spanner"></div>
            </div>
            <div class="paper"><img class="paper" src="./resources/paper_icon/cikm2023_cgec.png"
                title="FlaCGEC: A Chinese Grammatical Error Correction Dataset with Fine-grained Linguistic Annotation">
                <div><strong>FlaCGEC: A Chinese Grammatical Error Correction Dataset with Fine-grained Linguistic Annotation</strong><br>
                    Hanyue Du, Yike Zhao, Qingyuan Tian, Jiani Wang, Lei Wang, <strong>Yunshi Lan#</strong>, Xuesong Lu<br>
                    ACM CIKM, resource paper, 2023 <br>
                    <a href="https://github.com/hyDududu/FlaCGEC">[GitHub Page]</a>
                    <br>
                    We introduce a Chinese GEC dataset with fine-grained linguistic annotation. 
                </div>
                <div class="spanner"></div>
            </div>
        </div>
    </div>
    <br>

    <!--Grants-->
    <div style="clear: both;">
        <div class="section">
            <h2>Grants
            </h2>
            <div class="paper">
                <ul>
                    <li>
                        Jan. 2023 - Dec. 2025: Knowledge Base Question Answering System in Interactive Environments<br>
                        National Science Foundation of China, PI<br>
                    </li>
                </ul>
                <div class="spanner"></div>
                <ul>
                    <li>
                        Oct. 2022 - Sep. 2024: Knowledge Base Construction and Question Answering for an Education Intelligent Platform<br>
                        Shanghai Pujiang Talent Program, PI<br>
                    </li>
                </ul>
                <div class="spanner"></div>
                <ul>
                    <li>
                        July. 2022 - Dec. 2023: Online Education Toolkit and Platform Development for International Chinese Education<br>
                        East China Normal University, PI<br>
                    </li>
                </ul>
                <div class="spanner"></div>
                                <ul>
                    <li>
                        Aug. 2023 - Dec. 2023: Financial KBQA collaborating with Large Language Models<br>
                        Joint Reseach Program with Guotai Junan Securities<br>
                        <img class="company" src="./resources/paper_icon/guotaijunan.jpg">
                    </li>
                </ul>
                <div class="spanner"></div>
                <br>
            </div>
        </div>
    </div>

    <!--Teaching-->
    <div style="clear: both;">
        <div class="section">
            <h2>Teaching
            </h2>
            <div class="paper">
                <ul>
                    <li>
                        DATA0031132019.01 Deep Learning<br>
                        for both undergraduate students and postgraduate students
                    </li>
                </ul>
                <div class="spanner"></div>
                <br>
            </div>
        </div>
    </div>


    <!--Mentoring-->
    <div style="clear: both;">
        <div class="section">
            <h2>Mentoring Experience</h2>
            <div class="paper">
                <h4>Master</h4>
                <ul>
                    <li>
                        Zeyu Sheng (ECNU -> ByteDance, Shanghai)<br>
                        Xuyao Hu (ECNU -> Xiecheng, Shanghai)
                    </li>
                </ul>
                <div class="spanner"></div>
                <br>
            </div>
        </div>
    </div>

</body>

</html>
